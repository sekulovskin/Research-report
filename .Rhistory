for (kk in 1:K) {
bt[kk] <- b[kk] - mean(b[1:K])
}
tau.sigma[1] ~ dgamma(.1,.1)
tau.sigma[2] ~ dgamma(.1,.1)
sigma[1] <- 1/tau.sigma[1]
sigma[2] <- 1/tau.sigma[2]
}
"
####
## the data
R <- 2
Q <- 3
jags.data=list(Y=Y,N=N,W=W,X=X,J=J,K=K,R=R,Q=Q,group=group)
jags.inits <- function(){list(theta1 = rnorm(N), b = rnorm(K))}
jags.params <- c("sigma","b","gamma","beta")
jagsfit <- jags(data=jags.data,inits=jags.inits, jags.params, n.iter=5000, n.chains=2, model.file=textConnection(probitmodel2))
print(jagsfit)
probitmodel2 <- "model{
for(ii in 1:N) {
for(kk in 1:K) {
p[ii,kk] <- phi(theta1[ii] + theta2[group[ii]] - b[kk])
Y[ii,kk] ~ dbern(p[ii,kk])
}
}
for(ii in 1:N){	#prior person theta
theta1[ii] ~ dnorm(mu.theta1[ii], tau.sigma[1])
mu.theta1[ii] <- inprod(X[ii,],beta)
}
for(jj in 1:J){	#prior school theta
theta2[jj] ~ dnorm(mu.theta2[jj],tau.sigma[2])
mu.theta2[jj] <- inprod(W[jj,],gamma)
}
#Prior for item location parameters
for (kk in 1:K) {
b[kk] ~ dnorm(0, 0.001)
}
#Prior for level-1 effect
for(qq in 1:Q){
beta[qq] ~ dnorm(0,.001)
}
#Prior for level-2 effect
for(rr in 1:R) {
gamma[rr] ~ dnorm(0,.001)
}
#Rescaled Prior for item location parameters
for (kk in 1:K) {
bt[kk] <- b[kk] - mean(b[1:K])
}
tau.sigma[1] ~ dgamma(.1,.1)
tau.sigma[2] ~ dgamma(.1,.1)
sigma[1] <- 1/tau.sigma[1]
sigma[2] <- 1/tau.sigma[2]
}
"
####
## the data
R <- 2
Q <- 3
jags.data=list(Y=Y,N=N,W=W,X=X,J=J,K=K,R=R,Q=Q,group=group)
jags.inits <- function(){list(theta1 = rnorm(N), b = rnorm(K))}
jags.params <- c("sigma","b","gamma","beta")
jagsfit <- jags(data=jags.data,inits=jags.inits, jags.params, n.iter=5000, n.chains=2, model.file=textConnection(probitmodel2))
knitr::opts_chunk$set(echo = TRUE)
datasmoke <- read.csv("datasmoking2019.csv")
head(datasmoke)
smokeprobit <- glm(factor(smoker) ~ age + factor(gender), family = binomial(link = "probit"), data = datasmoke)
summary(smokeprobit)
smokeprobit <- glm(factor(smoker) ~ age + factor(gender), family = binomial(link = "probit"), data = datasmoke)
summary(smokeprobit)
smokeprobit <- glm(factor(smoker) ~ age + factor(gender), family = binomial(link = "probit"), data = datasmoke)
summary(smokeprobit)
smokeprobit <- glm(factor(smoker) ~ age + factor(gender), family = binomial(link = "probit"), data = datasmoke)
summary(smokeprobit)
View(datasmoke)
knitr::opts_chunk$set(echo = TRUE)
datasmoke <- read.csv("datasmoking2019.csv")
head(datasmoke)
smokeprobit <- glm(factor(smoker) ~ age + factor(gender), family = binomial(link = "probit"), data = datasmoke)
summary(smokeprobit)
library(ggplot2)
newdata <- data.frame(age = runif(100,min=-2,max=2),
gender = as.factor(sample(c("Girl","Boy"),100,replace=T)))
newdata[, c("p", "se")] <- predict(smokeprobit, newdata,
type = "response", se.fit = TRUE)[-3]
ggplot(newdata, aes(x = age, y = p,colour=gender)) + geom_line()
set.seed(1234)
Y <- as.numeric(as.factor(datasmoke$smoker))
X <- cbind(1,datasmoke$age,as.numeric(as.factor(datasmoke$gender))) # intercept, age, gender
N <- length(Y)
Z <- matrix(0,ncol=1,nrow=N) # Matrix for the augmented data
## starting values
beta <- c(0,0,0)
XB <- X%*%beta
# start sampling Z (Block 1)
uu <- runif(N)
Z1 <- qnorm(uu*pnorm(-XB)) + XB # Z <= 0
Z2 <- qnorm(uu*(1-pnorm(-XB))+pnorm(-XB)) + XB # Z > 0
Z[Y==1] <- Z1[Y==1] #store Z-values when Y==1
Z[Y==2] <- Z2[Y==2] #store Z-values when Y==2
View(X)
View(Z)
set.seed(1234)
Y <- as.numeric(as.factor(datasmoke$smoker))
X <- cbind(1,datasmoke$age,as.numeric(as.factor(datasmoke$gender))) # intercept, age, gender
N <- length(Y)
Z <- matrix(0,ncol=1,nrow=N) # Matrix for the augmented data
## starting values
beta <- c(0,0,0)
XB <- X%*%beta
# start sampling Z (Block 1)
uu <- runif(N)
Z1 <- qnorm(uu*pnorm(-XB)) + XB # Z <= 0
Z2 <- qnorm(uu*(1-pnorm(-XB))+pnorm(-XB)) + XB # Z > 0
Z[Y==1] <- Z1[Y==1] #store Z-values when Y==1
Z[Y==2] <- Z2[Y==2] #store Z-values when Y==2
View(Z1)
View(Z2)
#Sampling regression parameters (Block 2)
varb <- solve(t(X)%*%X) #covariance matrix
meanb <- varb%*%(t(X)%*%Z) #mean component
betan <- MASS::mvrnorm(1,mu=meanb,Sigma=varb) #simulate regression parameter values
XG <- 1 #specify number of MCMC iterations
Mbeta <- matrix(0,ncol=3,nrow=XG) #storage for sampled regression parameters
beta <- rnorm(3,mean=0,sd=.1) #initial random regression effects to get started
XB <- X%*%beta
for(xx in 1:XG){  #MCMC iterations
# Implement the data augmentation step
uu <- runif(N)
Z1 <- qnorm(uu*pnorm(-XB)) + XB # Z <= 0
Z2 <- qnorm(uu*(1-pnorm(-XB))+pnorm(-XB)) + XB # Z > 0
Z[Y==1] <- Z1[Y==1] #store Z-values when Y==1
Z[Y==2] <- Z2[Y==2] #store Z-values when Y==2
# Implement the sampling of regression effects
#Block 2
varb <- solve(t(X)%*%X) #covariance matrix
meanb <- varb%*%(t(X)%*%Z) #mean component
betan <- MASS::mvrnorm(1,mu=meanb,Sigma=varb)
XB <- X%*%betan
#Store Sampled Values
Mbeta[xx,] <- betan
}
XG <- 1000 #specify number of MCMC iterations
Mbeta <- matrix(0,ncol=3,nrow=XG) #storage for sampled regression parameters
beta <- rnorm(3,mean=0,sd=.1) #initial random regression effects to get started
XB <- X%*%beta
for(xx in 1:XG){  #MCMC iterations
# Implement the data augmentation step
uu <- runif(N)
Z1 <- qnorm(uu*pnorm(-XB)) + XB # Z <= 0
Z2 <- qnorm(uu*(1-pnorm(-XB))+pnorm(-XB)) + XB # Z > 0
Z[Y==1] <- Z1[Y==1] #store Z-values when Y==1
Z[Y==2] <- Z2[Y==2] #store Z-values when Y==2
# Implement the sampling of regression effects
#Block 2
varb <- solve(t(X)%*%X) #covariance matrix
meanb <- varb%*%(t(X)%*%Z) #mean component
betan <- MASS::mvrnorm(1,mu=meanb,Sigma=varb)
XB <- X%*%betan
#Store Sampled Values
Mbeta[xx,] <- betan
}
plot(Mbeta[,2],xlab="MCMC Iterations",ylab="Samples",xlim=c(0,XG),
ylim=c(.01,2),cex=.75,type="l",bty="l",lty=1)
lines(Mbeta[,3],col="red",cex=.75,lty=3)
legend("topright", c("Effect Age", "Effect Gender"),
col=c("black","red"),lty = c(1, 3),bg = "gray95",cex=.8)
View(Mbeta)
sd(Mbeta[,2])
sd(Mbeta[,3])
Probitmodel <- "model
{
for(i in 1:N){
Yn[i] ~ dbern(p[i])
p[i] <- phi(mu[i])
mu[i] <- beta_0 + beta_1 * Age + beta_2 * Gender
## priors
beta_0 ~ dnorm(0, 0.001)
beta_1 ~ dnorm(0, 0.001)
beta_2 ~ dnorm(0, 0.001)
}
"
library(R2jags)
jags.data <- list(Yn=(Y-1),N=N,Age=X[,2],Gender=X[,3])
jags.inits <- function(){list(beta = rnorm(3))}
jags.params <- c("beta")
jagsfit <- jags(data=jags.data,inits=jags.inits, jags.params, n.iter=1000, model.file=textConnection(Probitmodel))
Probitmodel <- "model
{
for(i in 1:N){
Yn[i] ~ dbern(p[i])
p[i] <- phi(mu[i])
mu[i] <- beta_0 + beta_1 * Age + beta_2 * Gender
## priors
beta_0 ~ dnorm(0, 0.001)
beta_1 ~ dnorm(0, 0.001)
beta_2 ~ dnorm(0, 0.001)
}"
library(R2jags)
jags.data <- list(Yn=(Y-1),N=N,Age=X[,2],Gender=X[,3])
jags.inits <- function(){list(beta = rnorm(3))}
jags.params <- c("beta_0", "beta_1", "beta_2")
jagsfit <- jags(data=jags.data,inits=jags.inits, jags.params, n.iter=1000, model.file=textConnection(Probitmodel))
Probitmodel <- "model
{
for(i in 1:N){
Yn[i] ~ dbern(p[i])
p[i] <- phi(mu[i])
mu[i] <- beta_0 + beta_1 * Age + beta_2 * Gender
}
## priors
beta_0 ~ dnorm(0, 0.001)
beta_1 ~ dnorm(0, 0.001)
beta_2 ~ dnorm(0, 0.001)
}"
library(R2jags)
jags.data <- list(Yn=(Y-1),N=N,Age=X[,2],Gender=X[,3])
jags.inits <- function(){list(beta = rnorm(3))}
jags.params <- c("beta_0", "beta_1", "beta_2")
jagsfit <- jags(data=jags.data,inits=jags.inits, jags.params, n.iter=1000, model.file=textConnection(Probitmodel))
Probitmodel <- "model
{
for(i in 1:N){
Yn[i] ~ dbern(p[i])
p[i] <- phi(mu[i])
mu[i] <- beta_0 + beta_1 * Age[i] + beta_2 * Gender[i]
}
## priors
beta_0 ~ dnorm(0, 0.001)
beta_1 ~ dnorm(0, 0.001)
beta_2 ~ dnorm(0, 0.001)
}"
library(R2jags)
jags.data <- list(Yn=(Y-1),N=N,Age=X[,2],Gender=X[,3])
jags.inits <- function(){list(beta = rnorm(3))}
jags.params <- c("beta_0", "beta_1", "beta_2")
jagsfit <- jags(data=jags.data,inits=jags.inits, jags.params, n.iter=1000, model.file=textConnection(Probitmodel))
#
#print(jagsfit)
#out <- attach.jags(jagsfit)
#
print(jagsfit)
plot(Mbeta[,2],xlab="MCMC Iterations",ylab="Samples",xlim=c(0,XG),
ylim=c(.01,2),cex=.75,type="l",bty="l",lty=1)
lines(Mbeta[,3],col="red",cex=.75,lty=3)
legend("topright", c("Effect Age", "Effect Gender","jags results"),
col=c("black","red","green"),lty = c(1, 3,5),bg = "gray95",cex=.8)
out <- attach.jags(jagsfit)
plot(Mbeta[,2],xlab="MCMC Iterations",ylab="Samples",xlim=c(0,XG),
ylim=c(.01,2),cex=.75,type="l",bty="l",lty=1)
lines(Mbeta[,3],col="red",cex=.75,lty=3)
legend("topright", c("Effect Age", "Effect Gender","jags results"),
col=c("black","red","green"),lty = c(1, 3,5),bg = "gray95",cex=.8)
library(R2jags)
jags.data <- list(Yn=(Y-1),N=N,Age=X[,2],Gender=X[,3])
jags.inits <- function(){list(beta = rnorm(3))}
jags.params <- c("beta_0", "beta_1", "beta_2")
jagsfit <- jags(data=jags.data,inits=jags.inits, jags.params, n.iter=1000, model.file=textConnection(Probitmodel))
#
print(jagsfit)
out <- attach.jags(jagsfit)
View(out)
plot(Mbeta[,2],xlab="MCMC Iterations",ylab="Samples",xlim=c(0,XG),
ylim=c(.01,2),cex=.75,type="l",bty="l",lty=1)
lines(Mbeta[,3],col="red",cex=.75,lty=3)
lines(out[["beta_1"]],col="red",cex=.75,lty=3)
lines(out[["beta_2"]],col="red",cex=.75,lty=3)
legend("topright", c("Effect Age", "Effect Gender","jags results"),
col=c("black","red","green"),lty = c(1, 3,5),bg = "gray95",cex=.8)
plot(Mbeta[,2],xlab="MCMC Iterations",ylab="Samples",xlim=c(0,XG),
ylim=c(.01,2),cex=.75,type="l",bty="l",lty=1)
lines(Mbeta[,3],col="red",cex=.75,lty=3)
lines(out[["beta_1"]],col="green",cex=.75,lty=3)
lines(out[["beta_2"]],col="green",cex=.75,lty=3)
legend("topright", c("Effect Age", "Effect Gender","jags results"),
col=c("black","red","green"),lty = c(1, 3,5),bg = "gray95",cex=.8)
beta0 <- 1 #effect of age
beta1 <- .5 #effect of gender
XB <- beta0*datasmoke$age #mean effect boys
XB[which(datasmoke$gender=="Girl")] <-
beta0*datasmoke$age[which(datasmoke$gender=="Girl")]+beta1 #mean effect girls
Z <- rnorm(N,mean=XB,sd=1) ## Simulate continuous normally
##distributed scores (augmented data)
## Truncate the continuous outcomes to categorical observations
Y[which(Z <= 0)] <- 1 #category smokes never
Y[which(Z > 0 & Z < 1)] <- 2 #category smokes sometimes
Y[which(Z > 1)] <- 3 #category smokes often
## Truncate the continuous outcomes to categorical observations
Y[which(Z <= 0)] <- 1 #category smokes never
Y[which(Z > 0 & Z < 1)] <- 2 #category smokes sometimes
Y[which(Z > 1)] <- 3 #category smokes often
alow <- bupp <- Z <- matrix(0,ncol=1,nrow=N)
G <- c(-Inf,0,1,Inf) # 3 response categories
alow[which(Y==1)] <- -Inf  #lowerbound Y==1
alow[which(Y>1)] <- G[Y][which(Y>1)] #lowerbound Y==2, Y==3
bupp <- G[Y+1] #upperbound Y==1,2,3
uu <- runif(N,min=pnorm(alow-XB),max=pnorm(bupp-XB))
Z <- XB + qnorm(uu)
plot(density(Z[Y==1],width=.75,to=max(Z[Y==1])),xlim=c(-4,4),ylim=c(0,1.2),lty=1,cex=.8,bty="l",main="",xlab="Augmented Value")
lines(density(Z[Y==2],width=.75,from=min(Z[Y==2]),to=max(Z[Y==2])),xlim=c(-4,4),ylim=c(0,1.1),lty=2,cex=.8)
lines(density(Z[Y==3],width=.75,from=min(Z[Y==3])),xlim=c(-4,4),ylim=c(0,1),lty=3,cex=.8)
abline(v=0,lty=1,lwd=.5,col="red")
abline(v=1,lty=1,lwd=.5,col="red")
library(foreign) #for loading the data
library(bain) #the wrapper function does not work without loading bain
source("wrapper_function.R") # load the wrapper function
library(lme4) #for multilevel modeling
library(jtools) #for nice summaries of lmer objects
library(psych) #fo
setwd("C:/Users/nikol/Desktop/MSc MSBBSS/Year-2_2021-2022/Master Thesis/Research report/Research-report")
dat <- read.spss(file = "tutorial.sav", to.data.frame = T)
library(foreign) #for loading the data
library(bain) #the wrapper function does not work without loading bain
source("wrapper_function.R") # load the wrapper function
library(lme4) #for multilevel modeling
library(jtools) #for nice summaries of lmer objects
library(psych) #
describe(dat)
x <- lmer(Examscore ~ 1 + LRTscore + AvsLRT + (LRTscore | School),
REML = F, data = dat)
summary(x) #for the default output
summ(x)
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 1, standardize = FALSE,N = "level_2" ,seed = 123)
#`fraction = 2`, i.e., 2 * b
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 2, standardize = FALSE, N = "level_2" ,seed = 123)
#`fraction = 3`, i.e., 3 * b
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 3, standardize = FALSE, N = "level_2" ,seed = 123)
#`fraction = 4`, i.e., 4 * b
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 4, standardize = FALSE, N = "level_2" ,seed = 123
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 4, standardize = FALSE, N = "level_2" ,seed = 123)
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 4, standardize = FALSE, N = "level_2" ,seed = 123)
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 1, standardize = FALSE, N = "level_2" ,seed = 123)
# Iteratively change the value of the argument `fraction`
#`fraction = 2`, i.e., 2 * b
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 2, standardize = FALSE, N = "level_2" ,seed = 123)
#`fraction = 3`, i.e., 3 * b
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 3, standardize = FALSE, N = "level_2" ,seed = 123)
#`fraction = 4`, i.e., 4 * b
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 4, standardize = FALSE, N = "level_2" ,seed = 123)
BF_o <- c(0.35, 0.25, 0.20, 0.17)
BF_i <- rep(4.21, 4)
# plot
par(mfrow = c(1, 2))
plot(BF_o, type = "l",  xaxt = "n", xlab = "times b", yaxt = "n", ylab = "BF", main = "(a)")
axis(1, at = 1:4)
axis(2, at = BF_o)
plot(BF_i, type = "l", xaxt = "n", yaxt = "n", xlab = "times b", ylab = "BF", main = "(b)")
axis(1, at = 1:4)
axis(2, at = BF_i)
library(foreign) #for loading the data
#######################################################################################
######## Analysis presented in the Research Report ###################################
#####################################################################################
#Sensitivity of Null Hypothesis Bayesian Testing in the context of two-level models#
###################################################################################
#IMPORTANT:
#1 set a working directory where the downloaded folder from GitHub is stored
#setwd("...")
#OR set it manually by clicking: Session -> Set Working Directory -> Choose Directory...
#2 In case the packages below do not load uncomment and run (some of) the following code:
#install.packages("foreign")
#install.packages("bain")
#install.packages("lme4")
#install.packages("jtools")
#install.packages("psych")
# Load the required packages -------------------------------------
library(foreign) #for loading the data
library(bain) #the wrapper function does not work without loading bain
source("wrapper_function.R") # load the wrapper function
library(lme4) #for multilevel modeling
library(jtools) #for nice summaries of lmer objects
library(psych) #for nice descriptive statistics
# Load the data -----------------------------------------------------------
dat <- read.spss(file = "tutorial.sav", to.data.frame = T)
#Additionally the data can be loaded directly from the `R2MLwiN` package, BUT NOTE
# in this case the data would contain many more variables (not used in this analysis)
#and additionally the naming of the variables is slightly different, here we will use
#the data loaded above
#library(R2MLwiN)
#data(tutorial)
# Descriptive statistics  -------------------------------------------------
describe(dat)
# Fit the two-level models using lmer -------------------------------------
x <- lmer(Examscore ~ 1 + LRTscore + AvsLRT + (LRTscore | School),
REML = F, data = dat)
summary(x) #for the default output
summ(x)  #for nicer output
# Use the wrapper to test the hypotheses using the default value for b ----------
#We use `standardize = FALSE`, since the data is already standardized by the original authors
#`N = "level_2" ` indicates that we will use the number of level 2 observations as the sample size
#We use `fraction = 1`
#All of this means we apply `b` = 2/65 = 0.03, i.e., 1 * 0.03
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 1, standardize = FALSE, N = "level_2" ,seed = 123)
# Iteratively change the value of the argument `fraction`
#`fraction = 2`, i.e., 2 * b
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 2, standardize = FALSE, N = "level_2" ,seed = 123)
#`fraction = 3`, i.e., 3 * b
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 3, standardize = FALSE, N = "level_2" ,seed = 123)
#`fraction = 4`, i.e., 4 * b
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 4, standardize = FALSE, N = "level_2" ,seed = 123)
# Obtain the plot in the paper --------------------------------------------
# store the results obtained above
BF_o <- c(0.35, 0.25, 0.20, 0.17)
BF_i <- rep(4.21, 4)
# plot
par(mfrow = c(1, 2))
plot(BF_o, type = "l",  xaxt = "n", xlab = "times b", yaxt = "n", ylab = "BF", main = "(a)")
axis(1, at = 1:4)
axis(2, at = BF_o)
plot(BF_i, type = "l", xaxt = "n", yaxt = "n", xlab = "times b", ylab = "BF", main = "(b)")
axis(1, at = 1:4)
axis(2, at = BF_i)
# END OF ANALYSIS ------------------------------------------------------
#######################################################################################
######## Analysis presented in the Research Report ###################################
#####################################################################################
#Sensitivity of Null Hypothesis Bayesian Testing in the context of two-level models#
###################################################################################
#IMPORTANT:
#1 set a working directory where the downloaded folder from GitHub is stored
#setwd("...")
#OR set it manually by clicking: Session -> Set Working Directory -> Choose Directory...
#2 In case (some of) the packages below do not load uncomment and run (some of) the following code:
#install.packages("foreign")
#install.packages("bain")
#install.packages("lme4")
#install.packages("jtools")
#install.packages("psych")
# Load the required packages -------------------------------------
library(foreign) #for loading the data
library(bain) #the wrapper function does not work without loading bain
library(lme4) #for multilevel modeling
library(jtools) #for nice summaries of lmer objects
library(psych) #for nice descriptive statistics
source("wrapper_function.R") # load the wrapper function
# Load the data -----------------------------------------------------------
dat <- read.spss(file = "tutorial.sav", to.data.frame = T)
#Additionally the data can be loaded directly from the `R2MLwiN` package, BUT NOTE
# in this case the data would contain many more variables (not used in this analysis)
#and additionally the naming of the variables is slightly different, here we will use
#the data loaded above
#library(R2MLwiN)
#data(tutorial)
# Descriptive statistics  -------------------------------------------------
describe(dat)
# Fit the two-level models using lmer -------------------------------------
x <- lmer(Examscore ~ 1 + LRTscore + AvsLRT + (LRTscore | School),
REML = F, data = dat)
summary(x) #for the default output
summ(x)  #for nicer output
# Use the wrapper to test the hypotheses using the default value for b ----------
#We use `standardize = FALSE`, since the data is already standardized by the original authors
#`N = "level_2" ` indicates that we will use the number of level 2 observations as the sample size
#We use `fraction = 1`
#All of this means we apply `b` = 2/65 = 0.03, i.e., 1 * 0.03
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 1, standardize = FALSE, N = "level_2" ,seed = 123)
# Iteratively change the value of the argument `fraction`
#`fraction = 2`, i.e., 2 * b
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 2, standardize = FALSE, N = "level_2" ,seed = 123)
#`fraction = 3`, i.e., 3 * b
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 3, standardize = FALSE, N = "level_2" ,seed = 123)
#`fraction = 4`, i.e., 4 * b
bain_2lmer(x, "LRTscore = AvsLRT = 0;
LRTscore = AvsLRT; LRTscore > 0 & AvsLRT >0",
fraction = 4, standardize = FALSE, N = "level_2" ,seed = 123)
# Obtain the plot in the paper --------------------------------------------
# store the results obtained above
BF_o <- c(0.35, 0.25, 0.20, 0.17)
BF_i <- rep(4.21, 4)
# plot
par(mfrow = c(1, 2))
plot(BF_o, type = "l",  xaxt = "n", xlab = "times b", yaxt = "n", ylab = "BF", main = "(a)")
axis(1, at = 1:4)
axis(2, at = BF_o)
plot(BF_i, type = "l", xaxt = "n", yaxt = "n", xlab = "times b", ylab = "BF", main = "(b)")
axis(1, at = 1:4)
axis(2, at = BF_i)
# END OF ANALYSIS ------------------------------------------------------
